{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_privacy as tfp\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(cifar10_train_images, cifar10_train_labels), (cifar10_test_images, cifar10_test_labels) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first image and its corresponding label from the training dataset\n",
    "sample_image = cifar10_train_images[0]\n",
    "sample_label = cifar10_train_labels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Access an image from the training dataset (e.g., the first image)\n",
    "sample_image = cifar10_train_images[0]\n",
    "\n",
    "# Convert to grayscale\n",
    "sample_image_gray = sample_image.mean(axis=2)  # Take the mean along the color channels\n",
    "\n",
    "# Display the grayscale image\n",
    "plt.imshow(sample_image_gray, cmap='gray')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: (32, 32, 3)\n",
      "Sample Label: [6]\n"
     ]
    }
   ],
   "source": [
    "# Display information about the sample image\n",
    "print(f\"Sample Image Shape: {sample_image.shape}\")\n",
    "print(f\"Sample Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess(images, labels):\n",
    "    images = tf.cast(images, tf.float32) / 255.0\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into multiple \"client\" datasets\n",
    "num_clients = 10\n",
    "client_datasets = []\n",
    "for i in range(num_clients):\n",
    "    start = i * len(cifar10_train_images) // num_clients\n",
    "    end = (i + 1) * len(cifar10_train_images) // num_clients\n",
    "    client_images = cifar10_train_images[start:end]\n",
    "    client_labels = cifar10_train_labels[start:end]\n",
    "    client_dataset = tf.data.Dataset.from_tensor_slices((client_images, client_labels))\n",
    "    client_dataset = client_dataset.map(preprocess).batch(20)\n",
    "    client_datasets.append(client_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential privacy is a mathematical technique that balances data privacy and data utility. It allows organizations to analyze and share private data without revealing sensitive information about individuals. Here’s how it works:\n",
    "\n",
    "#### Randomization: Differential privacy introduces controlled randomness (noise) into datasets. The goal is to prevent anyone from identifying specific individuals in the dataset.\n",
    "#### Privacy Budget (ε): Differential privacy uses a privacy loss parameter, often denoted as ε (epsilon). This parameter controls how much noise is added to the raw dataset. A higher ε value means more accurate but less private data.\n",
    "##### Example Process:\n",
    "Suppose you have a dataset with a column containing “Yes” or “No” answers from individuals.\n",
    "For each individual, you flip a coin:\n",
    "If it’s heads, you keep the answer as is.\n",
    "If it’s tails, you flip the coin again:\n",
    "Heads: Record the answer as “Yes.”\n",
    "Tails: Record the answer as “No.”\n",
    "This process adds randomness while maintaining aggregate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "def create_keras_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def model_fn_standard():\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=client_datasets[0].element_spec,\n",
    "        #It specifies the input specification based on the first client dataset (client_datasets[0].element_spec).\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "def model_fn_with_dp():\n",
    "    keras_model = create_keras_model()\n",
    "    optimizer = tfp.DPAdamGaussianOptimizer(\n",
    "        l2_norm_clip=1.0,\n",
    "        noise_multiplier=0.5,\n",
    "        num_microbatches=1,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    keras_model.compile(optimizer=optimizer,\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=client_datasets[0].element_spec,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In  model_fn_with_dp function, I have used the DPAdamGaussianOptimizer from the tensorflow_privacy library. This optimizer adds Gaussian noise to the gradients during the optimization process, which is a common technique for implementing differential privacy in deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights_to_keras_model(keras_model, tff_state):\n",
    "    tff_weights = tff_state.model.trainable\n",
    "    for var, tff_var in zip(keras_model.trainable_variables, tff_weights):\n",
    "        var.assign(tff_var)  # Removed .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(state, model_fn, test_dataset):\n",
    "    keras_model = create_keras_model()\n",
    "    assign_weights_to_keras_model(keras_model, state)\n",
    "\n",
    "    keras_model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    test_images, test_labels = zip(*list(test_dataset))\n",
    "    test_images = tf.concat(test_images, axis=0)\n",
    "    test_labels = tf.concat(test_labels, axis=0)\n",
    "\n",
    "    loss, accuracy = keras_model.evaluate(test_images, test_labels, verbose=0)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(dataset):\n",
    "    for batch in dataset.take(1):\n",
    "        images, labels = batch\n",
    "        print(f'Batch shape: {images.shape}, Labels: {labels.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[6]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [7]\n",
      " [8]\n",
      " [3]\n",
      " [4]\n",
      " [7]\n",
      " [7]\n",
      " [2]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [3]\n",
      " [2]\n",
      " [6]]\n",
      "Client 1 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[6]\n",
      " [7]\n",
      " [9]\n",
      " [0]\n",
      " [5]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [9]\n",
      " [0]\n",
      " [9]\n",
      " [2]\n",
      " [9]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [3]\n",
      " [9]\n",
      " [6]]\n",
      "Client 2 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[1]\n",
      " [6]\n",
      " [6]\n",
      " [8]\n",
      " [8]\n",
      " [3]\n",
      " [4]\n",
      " [6]\n",
      " [0]\n",
      " [6]\n",
      " [0]\n",
      " [3]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [8]\n",
      " [3]\n",
      " [2]\n",
      " [6]]\n",
      "Client 3 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[0]\n",
      " [6]\n",
      " [7]\n",
      " [0]\n",
      " [4]\n",
      " [9]\n",
      " [5]\n",
      " [8]\n",
      " [0]\n",
      " [4]\n",
      " [3]\n",
      " [8]\n",
      " [4]\n",
      " [7]\n",
      " [1]\n",
      " [8]\n",
      " [3]\n",
      " [5]\n",
      " [4]\n",
      " [5]]\n",
      "Client 4 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[8]\n",
      " [5]\n",
      " [0]\n",
      " [6]\n",
      " [9]\n",
      " [2]\n",
      " [8]\n",
      " [3]\n",
      " [6]\n",
      " [2]\n",
      " [7]\n",
      " [4]\n",
      " [6]\n",
      " [9]\n",
      " [0]\n",
      " [0]\n",
      " [7]\n",
      " [3]\n",
      " [7]\n",
      " [2]]\n",
      "Client 5 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[6]\n",
      " [9]\n",
      " [8]\n",
      " [4]\n",
      " [0]\n",
      " [6]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [9]\n",
      " [9]\n",
      " [8]\n",
      " [5]\n",
      " [8]\n",
      " [4]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [2]\n",
      " [3]]\n",
      "Client 6 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[0]\n",
      " [6]\n",
      " [0]\n",
      " [2]\n",
      " [7]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [1]]\n",
      "Client 7 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[5]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [1]\n",
      " [7]\n",
      " [9]\n",
      " [3]\n",
      " [7]\n",
      " [3]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [8]\n",
      " [8]\n",
      " [5]\n",
      " [3]\n",
      " [6]\n",
      " [8]\n",
      " [9]]\n",
      "Client 8 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[1]\n",
      " [8]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [7]\n",
      " [4]\n",
      " [3]\n",
      " [8]\n",
      " [2]\n",
      " [7]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [5]\n",
      " [9]\n",
      " [6]\n",
      " [2]\n",
      " [0]\n",
      " [8]]\n",
      "Client 9 dataset:\n",
      "Batch shape: (20, 32, 32, 3), Labels: [[7]\n",
      " [1]\n",
      " [4]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [9]\n",
      " [6]\n",
      " [0]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [8]\n",
      " [5]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "for i, client_dataset in enumerate(client_datasets):\n",
    "    print(f'Client {i} dataset:')\n",
    "    check_dataset(client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create federated averaging processes\n",
    "iterative_process_standard = tff.learning.build_federated_averaging_process(\n",
    "    model_fn_standard,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    ")\n",
    "\n",
    "iterative_process_with_dp = tff.learning.build_federated_averaging_process(\n",
    "    model_fn_standard,  # Use standard model_fn as DP optimizer will be applied in the client update\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Model - Round 0, metrics=OrderedDict([('sparse_categorical_accuracy', 0.17964), ('loss', 2.2078638)])\n",
      "Standard Model - Round 1, metrics=OrderedDict([('sparse_categorical_accuracy', 0.2609), ('loss', 2.0217845)])\n",
      "Standard Model - Round 2, metrics=OrderedDict([('sparse_categorical_accuracy', 0.30872), ('loss', 1.9185474)])\n"
     ]
    }
   ],
   "source": [
    "# Train the standard model\n",
    "NUM_ROUNDS = 3\n",
    "state_standard = iterative_process_standard.initialize()\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    state_standard, metrics_standard = iterative_process_standard.next(state_standard, client_datasets)\n",
    "    print(f'Standard Model - Round {round_num}, metrics={metrics_standard[\"train\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Model - Round 0, metrics=OrderedDict([('sparse_categorical_accuracy', 0.16242), ('loss', 2.236325)])\n",
      "DP Model - Round 1, metrics=OrderedDict([('sparse_categorical_accuracy', 0.24062), ('loss', 2.0594568)])\n",
      "DP Model - Round 2, metrics=OrderedDict([('sparse_categorical_accuracy', 0.29254), ('loss', 1.9599725)])\n"
     ]
    }
   ],
   "source": [
    "# Train the differentially private model\n",
    "state_with_dp = iterative_process_with_dp.initialize()\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    state_with_dp, metrics_with_dp = iterative_process_with_dp.next(state_with_dp, client_datasets)\n",
    "    print(f'DP Model - Round {round_num}, metrics={metrics_with_dp[\"train\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Model - Test loss: 1.7991496324539185, Test accuracy: 0.3668000102043152\n",
      "DP Model - Test loss: 1.8537687063217163, Test accuracy: 0.3522999882698059\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((cifar10_test_images, cifar10_test_labels))\n",
    "test_dataset = test_dataset.map(preprocess).batch(20)\n",
    "\n",
    "# Evaluate the standard model\n",
    "loss_standard, accuracy_standard = evaluate_model(state_standard, model_fn_standard, test_dataset)\n",
    "print(f'Standard Model - Test loss: {loss_standard}, Test accuracy: {accuracy_standard}')\n",
    "\n",
    "# Evaluate the differentially private model\n",
    "loss_with_dp, accuracy_with_dp = evaluate_model(state_with_dp, model_fn_with_dp, test_dataset)\n",
    "print(f'DP Model - Test loss: {loss_with_dp}, Test accuracy: {accuracy_with_dp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_fed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
